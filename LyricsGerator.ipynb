{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIY3S3BHzBOr06O48cmOU2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgreenfield/Song_Lyrics_Generator/blob/main/LyricsGerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cLZHXkmryqKf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf. __version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7yFvPGKEzCY",
        "outputId": "d521f413-6b30-4a2e-c667-df6e3a0edc46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('Juice_Wrld_Lyrics', \n",
        "      'https://raw.githubusercontent.com/rgreenfield/Song_Lyrics_Generator/main/Juice_Wrld_Lyrics')\n",
        "      "
      ],
      "metadata": {
        "id": "6U33MgJQyyHk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "data = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOCblWXRTE5O",
        "outputId": "39f817c7-eeb0-45e9-af6a-da02ebb14710"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'me': 1, 'with': 2, 'my': 3, 'i': 4, 'the': 5, \"i'm\": 6, 'drugs': 7, 'but': 8, 'and': 9, 'high': 10, 'if': 11, 'pop': 12, 'you': 13, 'smoke': 14, 'up': 15, 'bad': 16, 'oh': 17, \"don't\": 18, 'lean': 19, 'get': 20, 'fucked': 21, 'kidneys': 22, 'no': 23, 'whip': 24, 'rock': 25, 'drink': 26, 'liver': 27, 'some': 28, 'so': 29, 'hurt': 30, 'it': 31, 'too': 32, 'not': 33, 'a': 34, 'off': 35, \"swervin'\": 36, 'please': 37, 'urge': 38, 'know': 39, 'yeah': 40, 'phone': 41, 'to': 42, 'drive': 43, \"won't\": 44, 'show': 45, 'mercy': 46, 'yuh': 47, 'got': 48, \"lookin'\": 49, 'on': 50, 'die': 51, 'for': 52, 'love': 53, 'pills': 54, 'right': 55, 'huh': 56, 'turned': 57, 'whole': 58, 'different': 59, 'person': 60, 'crash': 61, 'bitch': 62, 'all': 63, \"screamin'\": 64, 'these': 65, 'hoes': 66, 'at': 67, 'is': 68, 'her': 69, 'real': 70, 'fuck': 71, 'two': 72, 'ring': 73, 'wrong': 74, 'when': 75, 'where': 76, 'belong': 77, 'they': 78, 'now': 79, 'sticks': 80, 'stones': 81, 'may': 82, 'break': 83, 'bones': 84, 'ex': 85, 'girlfriend': 86, 'keeps': 87, \"callin'\": 88, \"can't\": 89, 'worried': 90, 'alone': 91, 'did': 92, 'own': 93, 'bros': 94, 'pole': 95, 'be': 96, \"lurkin'\": 97, 'she': 98, \"sweatin'\": 99, 'room': 100, \"gettin'\": 101, 'colder': 102, 'devil': 103, 'angel': 104, 'shoulder': 105, 'will': 106, 'tonight': 107, 'over': 108, 'next': 109, 'closure': 110, 'told': 111, \"i'ma\": 112, 'young': 113, 'every': 114, 'day': 115, \"i've\": 116, 'been': 117, 'getting': 118, 'finally': 119, 'difference': 120, 'between': 121, 'shawty': 122, 'tell': 123, 'should': 124, 'really': 125, 'sober': 126, 'this': 127, 'shit': 128, \"ain't\": 129, 'fiction': 130, \"it's\": 131, 'one': 132, 'dose': 133, 'need': 134, 'looking': 135, 'trouble': 136, 'gonna': 137, 'find': 138, 'plug': 139, 'hit': 140, 'perfect': 141, 'timing': 142, 'girl': 143, 'hate': 144, \"that's\": 145, 'eyes': 146, 'red': 147, 'visine': 148, 'crashed': 149, 'mustang': 150, 'saleen': 151, 'beans': 152, 'laugh': 153, 'ask': 154, 'piss': 155, 'clean': 156, 'ayy': 157, 'gucci': 158, 'store': 159, 'come': 160, 'shop': 161, 'overdose': 162, 'bae': 163, 'are': 164, \"gon'\": 165, 'drop': 166, \"i'on\": 167, 'even': 168, 'wanna': 169, 'think': 170, 'about': 171, 'that': 172, \"let's\": 173, 'reach': 174, 'new': 175, 'height': 176, 'take': 177, 'shrooms': 178, 'same': 179, 'time': 180, 'went': 181, 'hollywood': 182, 'thrills': 183, 'from': 184, 'street': 185, 'life': 186, 'took': 187, 'many': 188, 'feel': 189, 'do': 190, 'irk': 191, 'dope': 192, 'perky': 193, 'lock': 194, \"'cause\": 195, \"lil'\": 196, 'hips': 197, 'curvy': 198, 'ride': 199, 'dick': 200, 'woah': 201}\n",
            "202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "8xy83GuWyykp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "metadata": {
        "id": "df-EeF1Sy13E"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "history = model.fit(predictors, label, epochs=50, verbose=1)\n",
        "#print model.summary()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtwuT0shzCdV",
        "outputId": "5ff00311-835a-40f4-be00-d4cfd45c2bca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - 6s 47ms/step - loss: 4.8294 - accuracy: 0.0862\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 4.0625 - accuracy: 0.1534\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 3.1573 - accuracy: 0.3155\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 2.2881 - accuracy: 0.4759\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 1.5537 - accuracy: 0.6207\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - 1s 48ms/step - loss: 0.9795 - accuracy: 0.7379\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.6639 - accuracy: 0.8293\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.4142 - accuracy: 0.8948\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.2333 - accuracy: 0.9448\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.1668 - accuracy: 0.9569\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.1215 - accuracy: 0.9655\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.0957 - accuracy: 0.9759\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.0839 - accuracy: 0.9724\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0694 - accuracy: 0.9776\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0568 - accuracy: 0.9724\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0607 - accuracy: 0.9776\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0572 - accuracy: 0.9776\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.0633 - accuracy: 0.9741\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.1025 - accuracy: 0.9707\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0566 - accuracy: 0.9707\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0680 - accuracy: 0.9759\n",
            "Epoch 22/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0576 - accuracy: 0.9759\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0451 - accuracy: 0.9810\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.0442 - accuracy: 0.9828\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.0472 - accuracy: 0.9793\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0619 - accuracy: 0.9810\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0658 - accuracy: 0.9810\n",
            "Epoch 28/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0497 - accuracy: 0.9793\n",
            "Epoch 29/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0510 - accuracy: 0.9776\n",
            "Epoch 30/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0427 - accuracy: 0.9810\n",
            "Epoch 31/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.0649 - accuracy: 0.9810\n",
            "Epoch 32/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.0545 - accuracy: 0.9793\n",
            "Epoch 33/50\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.0511 - accuracy: 0.9810\n",
            "Epoch 34/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0514 - accuracy: 0.9741\n",
            "Epoch 35/50\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 0.0474 - accuracy: 0.9793\n",
            "Epoch 36/50\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.0409 - accuracy: 0.9828\n",
            "Epoch 37/50\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.0502 - accuracy: 0.9741\n",
            "Epoch 38/50\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.0434 - accuracy: 0.9776\n",
            "Epoch 39/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0436 - accuracy: 0.9793\n",
            "Epoch 40/50\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.0434 - accuracy: 0.9741\n",
            "Epoch 41/50\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.0403 - accuracy: 0.9793\n",
            "Epoch 42/50\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.0425 - accuracy: 0.9759\n",
            "Epoch 43/50\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.0408 - accuracy: 0.9810\n",
            "Epoch 44/50\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 0.0399 - accuracy: 0.9741\n",
            "Epoch 45/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0392 - accuracy: 0.9793\n",
            "Epoch 46/50\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.0433 - accuracy: 0.9793\n",
            "Epoch 47/50\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.0602 - accuracy: 0.9793\n",
            "Epoch 48/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0540 - accuracy: 0.9793\n",
            "Epoch 49/50\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.0809 - accuracy: 0.9776\n",
            "Epoch 50/50\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0696 - accuracy: 0.9793\n",
            "<keras.engine.sequential.Sequential object at 0x7ff231ee0c10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"I'm the definition of a bandit\"\n",
        "next_words = 40\n",
        "  \n",
        "for i in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  #predicted = model.predict_classes(token_list, verbose=0)\n",
        "  predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "  output_word = \"\"\n",
        "  #print(predicted)\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    #print(word)\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-3ur9izzCf0",
        "outputId": "3e824f8d-8664-4d92-9035-1e9eeccb14a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "I'm the definition of a bandit trouble so i know i'm gonna find it on my own clean it shoulder it when i'm not wrong and shop with me so i'm not worried worried won't hurt me yuh yuh but me the drugs won't yuh yuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAWJXESXWiiQ",
        "outputId": "44b0e98f-b6a3-4d4d-f98d-bfeebc756bc3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm the definition of a bandit trouble so i know i'm gonna find it on my own clean it shoulder it when i'm not wrong and shop with me so i'm not worried worried won't hurt me yuh yuh but me the drugs won't yuh yuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3\n",
        "\n",
        "class TextToSpeech:\n",
        "    engine: pyttsx3.Engine\n",
        "\n",
        "    def __init__(self, voice, rate: int, volume: float):\n",
        "        self.engine = pyttsx3.init()\n",
        "        if voice:\n",
        "            self.engine.setProperty('voice', voice)\n",
        "        self.engine.setProperty('rate', rate)\n",
        "        self.engine.setProperty('volume', volume)  # Between 0 and 1\n",
        "\n",
        "    def text_to_speech(self, text: str, save: bool = False, file_name='output.mp3'):\n",
        "        self.engine.say(text)\n",
        "        print('I\\'m speaking...')\n",
        "\n",
        "        if save:\n",
        "            # On linux make sure that 'espeak' and 'ffmpeg' are installed\n",
        "            self.engine.save_to_file(text, file_name)\n",
        "\n",
        "        self.engine.runAndWait()\n",
        "\n",
        "    def list_available_voices(self):\n",
        "        voices: list = [self.engine.getProperty('voices')]\n",
        "\n",
        "        for i, voice in enumerate(voices[0]):\n",
        "            print(f'({i + 1}) {voice.name} {voice.age}: {voice.languages[0]} ({voice.gender}) [ID: {voice.id}]')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    tts = TextToSpeech('com.apple.speech.synthesis.voice.kyoko', 200, 1.0)\n",
        "    # tts.list_available_voices()\n",
        "    tts.text_to_speech(seed_text, save=True, file_name='output.mp3')"
      ],
      "metadata": {
        "id": "f9WDO70Ce-Kk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}